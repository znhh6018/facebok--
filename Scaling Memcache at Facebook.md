### Abstract
Memcached是一种众所周知的简单内存缓存解决方案。本文描述了Facebook如何利用memcached作为基础构件来构建和扩展一个分布式键值存储，以支持世界上最大的社交网络。我们的系统每秒可处理数十亿个请求，分发数以万亿的内容给全世界超过10亿的用户，为其提供丰富的体验。

### Introduction
流行和吸引人的社交网站是对基础设施的重大挑战。数亿人每天都使用这些网络，并施加计算、网络和I/O压力，传统的web架构很难满足需求。社交网络的基础架构需要
1. 允许近实时通信
2. 动态聚合来自多个来源的内容
3. 能够访问和更新非常流行的共享内容
4. 扩展到每秒处理数百万用户请求

我们描述了如何改进Memcached的开源版本，并将其用作基础构件为世界最大的社交网络，建立分布式键值存储。我们讨论了从单个服务器集群到分布全球各地的分布式集群的演化。据我们所知，该系统是全球范围内最大的memcached应用，每秒处理超过10亿个请求储存数以万亿计的数据。

这篇论文是最近发表的一系列作品中的最新一篇，该系列论文描述了分布式键值存储的灵活性和实用性。本文重点介绍内存哈希表的开源实现memcached，因为它以低成本提供对共享存储池的低延迟访问。这些特性使我们能够构建数据密集型功能，否则这些功能将不切实际。例如，一个特性：为每个页面请求发出数百个数据库查询，可能永远不会离开原型阶段，因为太慢太贵了。然而，在我们的应用中，网页通常会获取数千个来自memcached服务器的键值对。

我们的目标之一是展示出现在我们不同规模的部署中重要的主题。 虽然性能、效率、容错性、一致性等特性在所有尺度上都很重要，但是我们的经验表示在特定规模下，某些特性要求更难实现。在小范围内，维护数据一致性可能更容易。此外，随着服务器数量的增加和网络成为瓶颈，找到最佳通信计划的重要性也随之增加。

本文主要包括四个方面的贡献：
1. 我们描述了Facebook的基于memcached的演变架构
2. 我们实现了对memcached的增强，这些增强可以提高性能和内存效率
3. 我们强调了提高系统大规模运行能力的机制
4. 我们描述了加在系统上的production workload


### Overview
以下特性极大地影响了我们的设计。首先，用户消费的内容比他们创造的多一个数量级。 此行为会导致工作负载以获取数据为主，因此缓存可以有显着的优势。 二、我们的读操作从各种来源获取数据，例如MySQL 数据库、HDFS 安装和后端服务。 这种异质性需要灵活的缓存策略，以存储来自不同来源的数据。 

作为大型分布式系统中的基础组件，Memcached提供了一组简单的操作（set，get，delete）使其具有吸引力。我们开始使用的开源版本提供了一个单机版内存哈希表。在本文中，我们讨论如何利用这一基本构件，使其更有效率，并用它来建立一个分布式键值存储，每秒可以处理数十亿个请求。我们使用“memcached”来表示源代码或正在运行的二进制文件，使用“memcache”来描述分布式系统。

+ 查询缓存
我们依靠memcache减轻数据库的读负载。特别是，我们使用memcache作为一个按需填充的look-aside（后备）缓存。
  + 读请求，首先通过key从memcache获取值。如果由该key没有缓存，则web服务器从数据库或其他后端服务检索数据，并用键值填充缓存。
  + 写请求，web服务器向数据库发出SQL语句，然后向数据库发送删除请求，使任何陈旧数据无效。我们选择删除缓存数据而不是更新它，因为
是幂等的。Memcache不是数据的权威来源，因此允许删除缓存的数据。

虽然有几种方法可以解决MySQL数据库上过多的读请求，但我们选择使用memcache。考虑到有限的工程资源和时间，这是最好的选择。此外，将缓存层与持久性层分离，允许我们在workload变化时独立调整每一层。

+ 通用缓存
我们还利用memcache作为更通用的键值存储。例如，工程师使用memcache存储复杂的机器学习算法的预计算结果，然后这些结果可以被其他各种应用程序使用。新服务利用现有marcher基础设施而无需调整、优化、资源调配和维护大型服务集群。 

目前，memcached不提供服务器到服务器的协调；它是在单个服务器上运行的内存哈希表。在本文的剩余部分中，我们将描述如何基于memcached构建分布式键值存储，该存储能够在Facebook的workload下运行。我们的系统提供了一套配置、聚合和路由服务来组织
memcached实例到分布式系统中。

论文主要讨论了在三种不同部署规模下出现的问题。当我们只有一个服务器集群时，我们最关心的是繁重的读负载和数据库的读取。由于需要扩展到多个前端集群，我们将解决这些集群之间的数据复制问题。最后，我们描述了在全世界范围内扩展集群时提供一致用户体验的机制。操作复杂性和容错性在所有规模上都很重要。我们提供了支持我们的设计决策的重要数据，并建议读者参考Atikoglu等人的工作，以便对我们的workload进行更详细的分析。At a high level，图2说明了最终的体系结构，在该体系结构中，我们将位于同一位置的集群组织到一个区域中，并指定一个master区域，该区域提供数据流以使 非master 区域保持最新。

在改进系统时，我们优先考虑两个主要的设计目标
1. 任何更改都必须影响用户面临的问题或操作问题,不考虑范围有限的优化。
2. 我们将读取瞬态陈旧数据的概率视为需要调整的参数，类似于响应性。我们可能会提供稍微过期的数据，以避免后端存储服务负载过大。

### 一个集群中：延迟和负载
现在我们考虑一个集群扩展到数千台服务器的挑战。在这种规模下，我们的大部分工作都集中在减少获取缓存数据的延迟或由于缓存未命中而造成的负载。

#### 减少延迟
不管数据请求是否会命中缓存或未命中，对于用户请求的响应时间来说，memcache响应的延迟是一个关键因素。 
我们在集群中提供数百个memcached服务器，以减少数据库和其他服务的负载。通过一致性哈希算法，分布在memcached服务器上。因此，web服务器必须定期与许多memcached服务器通信以满足用户请求。因此，所有web服务器都可以在短时间内与每个memcached服务器通信。这种all-to-all的通信模式可能会导致拥塞，或者使单个服务器成为许多web服务器的瓶颈。数据复制通常会缓解单服务器瓶颈，但通常会导致系统内存效率显著降低。

我们主要通过关注运行在每个web服务器上的memcache客户端来减少延迟。该客户端提供一系列功能，包括序列化、压缩、请求路由、错误处理和请求批处理。客户端维护所有可用服务器的映射，并通过辅助配置系统进行更新。

+ 并行请求和批处理 
我们构造web应用程序代码以最小化响应页面请求所需的网络往返次数。我们构造了一个有向无环图（DAG），表示数据之间的依赖关系。web服务器使用此DAG选项最大化，可以同时获取的数据。这些批处理平均每个请求包含24个key。
+ 客户端-服务器通信
Memcached服务器之间不通信。在适当的时候，我们将系统的复杂性嵌入到无状态客户机中，而不是memcached服务器中。这大大简化了memcached，并允许我们专注于使其在更有限的用例中具有更高的性能。保持客户端无状态可以在软件中进行快速迭代，并简化部署过程。客户机逻辑作为两个组件提供：一个可以嵌入到应用程序中或作为名为的mcrouter独立代理。此代理提供了一个memcached服务器接口，并将请求/答复路由到/来自其他服务器。


客户端使用UDP和TCP与memcached服务器通信。我们依靠UDP获取请求以减少延迟和开销。由于UDP是无连接的，允许web服务器中的每个线程直接与memcached服务器通信，绕过mcrouter，无需建立和维护连接，从而减少开销。UDP的实现中，检测丢弃或无序接收的数据包（使用序列号）并进行处理，它们在客户端被视为错误。它没有提供任何试图从中恢复的机制。在我们的基础架构方面，我们认为这个决定是切实可行的。
在峰值负载下，memcache客户端观察到0.25%的get请求被丢弃。大约80%的这些下降是由于数据包延迟或丢失，而其余的都是由于数据包顺序错误。客户端将get错误视为缓存未命中，但web服务器在查询数据后会跳过将数据插入memcached，以避免在可能过载的网络或服务器上增加额外负载。为了可靠性，客户端采用TCP，通过与web服务器运行在同一台机器上的mcrouter实例执行设置和删除操作。对于需要确认状态更改（更新和删除）的操作，TCP减轻了向我们自实现的UDP实现添加重试机制的需要。

Web服务器依赖于高度的并行性和过度订阅（over-subscription）以实现高吞吐量。开放TCP连接的高内存需求使得，如果不通过mcrouter进行某种形式的连接合并，直接在每个web线程和memcached服务器之间建立开放连接成本过高。在高吞吐量TCP连接下，合并这些连接可以减少网络、CPU和内存所需的资源，从而提高服务器的效率。图3展示了web服务器在生产环境下，通过UDP和通过mcrouter的TCP，获取key的延迟的平均值、中位数以及95%分位。在所有情况下，这些平均值的标准偏差均小于1%。如数据所示，依赖UDP可以使服务器请求的延迟减少20%。

+ 增加阻塞（Incast congestion）
Memcache客户端实现流量控制机制以限制增量拥塞。当客户端请求大量key时，如果这些响应同时到达，则响应可能会使机架和群集交换机等组件崩溃。因此，客户端使用滑动窗口机制来控制未处理的请求数。当客户端收到响应时，可以发送下一个请求。此滑动窗口的大小在成功的请求下缓慢增长，并当一个请求没有得到响应时收缩。该窗口独立于目的地应用于所有memcache请求，而TCP窗口仅适用于单个流。

图4显示了窗口大小对用户请求处于可运行状态，但是等待web服务器内部进行调度的时间的影响。数据是从一个前端集群中的多个机架收集的。用户请求在每个web服务器上都表现出泊松到达过程。根据利特尔定律，L=λW，服务器中排队的请求数（L） 与处理请求所需的平均时间（W）成正比，假设输入请求速率是恒定的（这是我们实验的结果）。web请求等待调度的时间可以直接反映系统中web请求数。使用较小的窗口大小，应用程序将不得不连续发送更多组的memcache请求，从而增加web请求的持续时间。随着窗口大小变得太大，同时出现的memcache请求会导致增量拥塞。结果将导致memcache错误，应用程序将返回到数据的持久存储去查找数据，这将导致web请求的处理速度变慢。在这两个极端之间有一个平衡点，即可以避免不必要的延迟，并且可以最小化增量拥塞。

### 减小负载
我们使用memcache来减少沿着更昂贵的路径（如数据库查询）获取数据的频率。当所需数据未缓存时，Web服务器会退回到这些路径。以下小节描述了三种降低负载的技术。

#### 租赁
我们引入了一种新的机制，我们称之为租赁来解决这两个问题：stale set 和 thundering herds。
当web服务器在memcache中设置一个过期的值时，称之为stale set，它不反映应缓存的最新值。当对memcache的并发更新顺序错乱时，可能会发生这种情况。

当一个特定的键经历了大量的读写活动时，就会发生thundering herds。

由于反复写入活动会使最近设置的值无效，因此许多读取操作需要反复读取数据库。我们的租赁机制解决了这两个问题。