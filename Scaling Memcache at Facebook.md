### Abstract
Memcached是一种众所周知的简单内存缓存解决方案。本文描述了Facebook如何利用memcached作为基础构件来构建和扩展一个分布式键值存储，以支持世界上最大的社交网络。我们的系统每秒可处理数十亿个请求，分发数以万亿的内容给全世界超过10亿的用户，为其提供丰富的体验。

### Introduction
流行和吸引人的社交网站是对基础设施的重大挑战。数亿人每天都使用这些网络，并施加计算、网络和I/O压力，传统的web架构很难满足需求。社交网络的基础架构需要
1. 允许近实时通信
2. 动态聚合来自多个来源的内容
3. 能够访问和更新非常流行的共享内容
4. 扩展到每秒处理数百万用户请求

我们描述了如何改进Memcached的开源版本，并将其用作基础构件为世界最大的社交网络，建立分布式键值存储。我们讨论了从单个服务器集群到分布全球各地的分布式集群的演化。据我们所知，该系统是全球范围内最大的memcached应用，每秒处理超过10亿个请求储存数以万亿计的数据。

这篇论文是最近发表的一系列作品中的最新一篇，该系列论文描述了分布式键值存储的灵活性和实用性。本文重点介绍内存哈希表的开源实现memcached，因为它以低成本提供对共享存储池的低延迟访问。这些特性使我们能够构建数据密集型功能，否则这些功能将不切实际。例如，一个特性：为每个页面请求发出数百个数据库查询，可能永远不会离开原型阶段，因为太慢太贵了。然而，在我们的应用中，网页通常会获取数千个来自memcached服务器的键值对。

我们的目标之一是展示出现在我们不同规模的部署中重要的主题。 虽然性能、效率、容错性、一致性等特性在所有尺度上都很重要，但是我们的经验表示在特定规模下，某些特性要求更难实现。在小范围内，维护数据一致性可能更容易。此外，随着服务器数量的增加和网络成为瓶颈，找到最佳通信计划的重要性也随之增加。

本文主要包括四个方面的贡献：
1. 我们描述了Facebook的基于memcached的演变架构
2. 我们实现了对memcached的增强，这些增强可以提高性能和内存效率
3. 我们强调了提高系统大规模运行能力的机制
4. 我们描述了加在系统上的production workload


### Overview
以下特性极大地影响了我们的设计。首先，用户消费的内容比他们创造的多一个数量级。 此行为会导致工作负载以获取数据为主，因此缓存可以有显着的优势。 二、我们的读操作从各种来源获取数据，例如MySQL 数据库、HDFS 安装和后端服务。 这种异质性需要灵活的缓存策略，以存储来自不同来源的数据。 

作为大型分布式系统中的基础组件，Memcached提供了一组简单的操作（set，get，delete）使其具有吸引力。我们开始使用的开源版本提供了一个单机版内存哈希表。在本文中，我们讨论如何利用这一基本构件，使其更有效率，并用它来建立一个分布式键值存储，每秒可以处理数十亿个请求。我们使用“memcached”来表示源代码或正在运行的二进制文件，使用“memcache”来描述分布式系统。

+ 查询缓存
我们依靠memcache减轻数据库的读负载。特别是，我们使用memcache作为一个按需填充的look-aside（后备）缓存。
  + 读请求，首先通过key从memcache获取值。如果由该key没有缓存，则web服务器从数据库或其他后端服务检索数据，并用键值填充缓存。
  + 写请求，web服务器向数据库发出SQL语句，然后向数据库发送删除请求，使任何陈旧数据无效。我们选择删除缓存数据而不是更新它，因为
是幂等的。Memcache不是数据的权威来源，因此允许删除缓存的数据。

虽然有几种方法可以解决MySQL数据库上过多的读请求，但我们选择使用memcache。考虑到有限的工程资源和时间，这是最好的选择。此外，将缓存层与持久性层分离，允许我们在workload变化时独立调整每一层。

+ 通用缓存
我们还利用memcache作为更通用的键值存储。例如，工程师使用memcache存储复杂的机器学习算法的预计算结果，然后这些结果可以被其他各种应用程序使用。新服务利用现有marcher基础设施而无需调整、优化、资源调配和维护大型服务集群。 

目前，memcached不提供服务器到服务器的协调；它是在单个服务器上运行的内存哈希表。在本文的剩余部分中，我们将描述如何基于memcached构建分布式键值存储，该存储能够在Facebook的workload下运行。我们的系统提供了一套配置、聚合和路由服务来组织
memcached实例到分布式系统中。

论文主要讨论了在三种不同部署规模下出现的问题。当我们只有一个服务器集群时，我们最关心的是繁重的读负载和数据库的读取。由于需要扩展到多个前端集群，我们将解决这些集群之间的数据复制问题。最后，我们描述了在全世界范围内扩展集群时提供一致用户体验的机制。操作复杂性和容错性在所有规模上都很重要。我们提供了支持我们的设计决策的重要数据，并建议读者参考Atikoglu等人的工作，以便对我们的workload进行更详细的分析。At a high level，图2说明了最终的体系结构，在该体系结构中，我们将位于同一位置的集群组织到一个区域中，并指定一个master区域，该区域提供数据流以使 非master 区域保持最新。

在改进系统时，我们优先考虑两个主要的设计目标
1. 任何更改都必须影响用户面临的问题或操作问题,不考虑范围有限的优化。
2. 我们将读取瞬态陈旧数据的概率视为需要调整的参数，类似于响应性。我们可能会提供稍微过期的数据，以避免后端存储服务负载过大。

### 一个集群中：延迟和负载
现在我们考虑一个集群扩展到数千台服务器的挑战。在这种规模下，我们的大部分工作都集中在减少获取缓存数据的延迟或由于缓存未命中而造成的负载。

#### 减少延迟
不管数据请求是否会命中缓存或未命中，对于用户请求的响应时间来说，memcache响应的延迟是一个关键因素。 
我们在集群中提供数百个memcached服务器，以减少数据库和其他服务的负载。通过一致性哈希算法，分布在memcached服务器上。因此，web服务器必须定期与许多memcached服务器通信以满足用户请求。因此，所有web服务器都可以在短时间内与每个memcached服务器通信。这种all-to-all的通信模式可能会导致拥塞，或者使单个服务器成为许多web服务器的瓶颈。数据复制通常会缓解单服务器瓶颈，但通常会导致系统内存效率显著降低。

我们主要通过关注运行在每个web服务器上的memcache客户端来减少延迟。该客户端提供一系列功能，包括序列化、压缩、请求路由、错误处理和请求批处理。客户端维护所有可用服务器的映射，并通过辅助配置系统进行更新。

+ 并行请求和批处理 
我们构造web应用程序代码以最小化响应页面请求所需的网络往返次数。我们构造了一个有向无环图（DAG），表示数据之间的依赖关系。web服务器使用此DAG选项最大化，可以同时获取的数据。这些批处理平均每个请求包含24个key。
+ 客户端-服务器通信
Memcached服务器之间不通信。在适当的时候，我们将系统的复杂性嵌入到无状态客户机中，而不是memcached服务器中。这大大简化了memcached，并允许我们专注于使其在更有限的用例中具有更高的性能。保持客户端无状态可以在软件中进行快速迭代，并简化部署过程。客户机逻辑作为两个组件提供：一个可以嵌入到应用程序中或作为名为的mcrouter独立代理。此代理提供了一个memcached服务器接口，并将请求/答复路由到/来自其他服务器。


